{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainHelper.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWWZTmpIYPwTdsWau0gWre",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelXJames/Auto-Music-Seperation/blob/main/trainHelper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zN-OZN5JlG3"
      },
      "source": [
        "## Clone Music Seperation and Add to Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb2Mzc9dYOpU",
        "outputId": "b2458978-6551-4036-9a46-cec000fe8c72"
      },
      "source": [
        "!git clone https://github.com/SamuelXJames/Auto-Music-Seperation.git\n",
        "import sys\n",
        "sys.path.append('/content/Auto-Music-Seperation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Auto-Music-Seperation'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 180 (delta 84), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (180/180), 357.84 KiB | 9.67 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUpzxPCqYOpV"
      },
      "source": [
        "## Change Collab's Timezone to EST\n",
        "The current time is used in the filename of Tensorfboard logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz5sohoTYOpW"
      },
      "source": [
        "#Changes Colab's Timezone - Soft restart for this to work\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/America/New_York /etc/localtime\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPAwx8AwYOpW"
      },
      "source": [
        "## Load Tensorboard\n",
        "Here \"logs\" is the folder where all of the Tensorboard logs are saved. Collab will create a folder called \"logs\" and save the files in here. This means all of the log directory files will be deleted when the session stops. Mounting Google Drive and then pointing the logdir to a Drive folder may be a better approach.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_-ee_l1YOpW"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs #(ie. a new folder calls logs - alternativly use drive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGzqWFpvtKau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2458978-6551-4036-9a46-cec000fe8c72"
      },
      "source": [
        "!git clone https://github.com/SamuelXJames/Auto-Music-Seperation.git\n",
        "import sys\n",
        "sys.path.append('/content/Auto-Music-Seperation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Auto-Music-Seperation'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 180 (delta 84), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (180/180), 357.84 KiB | 9.67 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evxCYhV6Js4Y"
      },
      "source": [
        "## Change Collab's Timezone to EST\n",
        "The current time is used in the filename of Tensorfboard logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A73K9xrNWJ_0"
      },
      "source": [
        "#Changes Colab's Timezone - Soft restart for this to work\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/America/New_York /etc/localtime\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVESfhlAJ8sL"
      },
      "source": [
        "## Load Tensorboard\n",
        "Here \"logs\" is the folder where all of the Tensorboard logs are saved. Collab will create a folder called \"logs\" and save the files in here. This means all of the log directory files will be deleted when the session stops. Mounting Google Drive and then pointing the logdir to a Drive folder may be a better approach.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D57VY8hiVIwH"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs #(ie. a new folder calls logs - alternativly use drive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh6r5xreLSQe"
      },
      "source": [
        "## Download Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddXsSVNxLVPk"
      },
      "source": [
        "!pip install -r \"/content/Auto-Music-Seperation/requirements.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoHbLpguYVfD"
      },
      "source": [
        "## Setup Training Parameters\n",
        "\n",
        "- **model**: \"cunet\" or \"sr\" - the nueral network to use\n",
        "- **train_path**: folder containing the training TFRecords\n",
        "- **valid_path**: folder containing the validation TFRecords\n",
        "- **progress_folder**: folder containing the progress images\n",
        "  - The progress images are spectrograms periodically input into the model to see the training's progress\n",
        "- **progress_save_folder**: The folder to save the output of the model when progress images have been input\n",
        "- **progress_freq**: Frequency in epochs to input the progress images into the model\n",
        "- **test_path\\***: folder containing TFRecords of the Test Dataset\n",
        "- **weights_path\\*\\***: path to any saved weights to continue training\n",
        "- **batch_size**: Number of images before weights are updated\n",
        "  - use multiples of 32 up to 256\n",
        "  - tradeoff between speed and learning ability\n",
        "- **epochs**: Number of times the model is trained on the entire dataset\n",
        "  - recomended to set this as arbitraily large\n",
        "- **learning_rate_params**: uses a [linearily diminishing cycliclal learning rate](https://pyimagesearch.com/wp-content/uploads/2019/07/keras_clr_triangular2.png)\n",
        "  - *cycle_rate*: Rate in epochs for a single cycle\n",
        "  - *min*: minimum learning rate\n",
        "  - *max*: peak learning rate\n",
        "  - *start*: learning rate at epoch 1\n",
        "\n",
        "- **learning_function\\***: An alternative learning function can be input in place of a cyclical learning rate\n",
        "  - Should by an array with each value being the learning rate at a specific epoch\n",
        "- **adam_optimizer**: adam_optimizer parameters\n",
        "- **loss**: loss function\n",
        "  - [Should be a string](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
        "- **steps_per_execution**: Not sure what this is. A larger number might run everything faster. Or it might not work at all\n",
        "- **save_freq**: frequency in epochs to save the model\n",
        "- **cache**: Weather to cache the data or not\n",
        "  - cache data allows it to be read faster\n",
        "  - Not sure if all the data will fit in cache\n",
        "- **tpu**: If you are using a TPU set to True otherwise False  \n",
        "\n",
        "\\* Optional  \n",
        "\\** When you first start training this should be empty. Include the weights path when you are returning to training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Rwfzh6YT1e"
      },
      "source": [
        "import trainer as Trainer()\n",
        "\n",
        "trainer = Trainer(model, \n",
        "                  save_path,\n",
        "                  train_path,\n",
        "                  valid_path,\n",
        "                  progress_folder = None,\n",
        "                  progress_save_folder = None,\n",
        "                  progress_freq = 5,\n",
        "                  test_path = None, \n",
        "                  weights_path = None,\n",
        "                  batch_size = 32,\n",
        "                  epochs = 1000,\n",
        "                  learning_rate_params={'cycle': 9, \n",
        "                                        'min': 0.001, \n",
        "                                        'max': 0.005,\n",
        "                                        'start':0.001},\n",
        "                  learning_function = None,\n",
        "                  adam_optimizer={'beta1': 0.9, \n",
        "                                  'beta2': 0.999, \n",
        "                                  'epsilon': None},\n",
        "                  loss = 'mae',\n",
        "                  steps_per_execution = 1,\n",
        "                  save_freq = 5,\n",
        "                  cache = False,\n",
        "                  tpu = False):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLmM_gBwfgUR"
      },
      "source": [
        "## Plot Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxhWRclsfTWu"
      },
      "source": [
        "train.plot_lr_scheduler(epochs = 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Gcx93DfiP9"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFuEoEBBfQS1"
      },
      "source": [
        "trainer.train"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}