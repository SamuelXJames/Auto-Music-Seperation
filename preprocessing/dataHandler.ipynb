{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataHandler.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOz5/KI9zgcP385uzzFFwTd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelXJames/Auto-Music-Seperation/blob/main/preprocessing/dataHandler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXCB6lhnu0TG"
      },
      "source": [
        "import numpy as np\n",
        "import os, sys, math, glob, ntpath,time\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "class dataHandler:\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    \n",
        "    return None\n",
        "  \n",
        "  \n",
        "  def listFiles(self,tfr_dir,partion = None):\n",
        "    files = tf.data.Dataset.list_files(os.path.join(tfr_dir,'*.tfrec'))\n",
        "    \n",
        "    if partion:\n",
        "      files = files.batch(partion)\n",
        "      files = list(files.as_numpy_iterator())\n",
        "  \n",
        "    return files\n",
        "  \n",
        "  \n",
        "  @tf.function\n",
        "  def get_tfrecord(self,GCS_File):\n",
        "    dataset = tf.data.TFRecordDataset(GCS_File,compression_type='ZLIB', \n",
        "                                      num_parallel_reads = tf.data.AUTOTUNE)\n",
        "    #dataset = dataset.batch(32)\n",
        "    return dataset\n",
        "\n",
        "  @tf.function\n",
        "  def read_tfrecord(self,example):\n",
        "    #Write this info into the filename\n",
        "    nb_images = 1000\n",
        "    HR_IMG_SHAPE = [84,84]\n",
        "    LR_IMG_SHAPE = [21,21]\n",
        "    NUM_CHANNELS = 3\n",
        "  # Create a dictionary describing the features.\n",
        "    features = {\n",
        "        'HR': tf.io.FixedLenFeature([], tf.string),\n",
        "        'HR_label': tf.io.FixedLenFeature([], tf.string),\n",
        "        'LR': tf.io.FixedLenFeature([], tf.string),\n",
        "        'LR_label': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    \n",
        "    example = tf.io.parse_example(example, features)\n",
        "\n",
        "    HR = tf.map_fn(tf.io.decode_png, example['HR'], fn_output_signature=tf.uint8)\n",
        "    HR = tf.map_fn(lambda HR: tf.reshape(HR, [HR_IMG_SHAPE[0],HR_IMG_SHAPE[1], NUM_CHANNELS]), HR)\n",
        "\n",
        "    LR = tf.map_fn(tf.io.decode_png, example['LR'], fn_output_signature=tf.uint8)\n",
        "    LR = tf.map_fn(lambda LR: tf.reshape(LR, [LR_IMG_SHAPE[0],LR_IMG_SHAPE[1], NUM_CHANNELS]), LR)\n",
        "    \n",
        "    HR_label = example['HR_label']\n",
        "    LR_label = example['LR_label']\n",
        "    \n",
        "    return HR,HR_label,LR,LR_label\n",
        "  \n",
        "  def build_dataset(self,dataset, batch_size):\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.experimental_deterministic = False\n",
        "\n",
        "    #If the input is an array of file names, convert it to a dataset\n",
        "    if type(dataset) == np.ndarray:\n",
        "      dataset = tf.data.Dataset.from_tensor_slices(dataset)  \n",
        "    \n",
        "\n",
        "    dataset = dataset.interleave(self.get_tfrecord,\n",
        "                                 block_length = 1,\n",
        "                                 cycle_length = tf.data.AUTOTUNE,\n",
        "                                 num_parallel_calls = tf.data.AUTOTUNE)\n",
        "    \n",
        "    dataset = dataset.batch(batch_size, drop_remainder = True)\n",
        "  \n",
        "    dataset = dataset.map(self.read_tfrecord,num_parallel_calls = tf.data.AUTOTUNE)\n",
        "    \n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU8J7XcEs4gN"
      },
      "source": [
        "#EXAMPLE\n",
        "# dh = dataHandler()\n",
        "# files = dh.listFiles('', partion=3)\n",
        "# for partion in files:\n",
        "#   ds = dh.build_dataset(partition, 32)\n",
        "#   for (HR,HR_label,LR,LR_label) in ds.take(-1):\n",
        "#       print('HR Shape: ' + str(np.shape(HR)) + ' LR Shape: ' + str(np.shape(LR)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNYKf9Dlno7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3bb9b7-9bdf-42b4-8d8d-380284cfc43c"
      },
      "source": [
        "#Different Methods to get batch\n",
        "# ds = ds.cache() #if aplicable\n",
        "# def a1():\n",
        "#   count = 0 \n",
        "#   for i,(HR,HR_label,LR,LR_label)  in enumerate(ds):\n",
        "#     count = count + 1\n",
        "#   return count\n",
        "\n",
        "# def a2():\n",
        "#   count = 0\n",
        "#   for i in range(63):\n",
        "#     count = count + 1\n",
        "#   return count\n",
        "# #tfds.core.benchmark\n",
        "\n",
        "# def a3():\n",
        "#   count = 0\n",
        "#   for i in range(63):\n",
        "#     HR,HR_label,LR,LR_label = next(iter(ds))\n",
        "#     count = count + 1\n",
        "#   return count\n",
        "\n",
        "# def a4():\n",
        "#   count = 0\n",
        "#   for element in ds.as_numpy_iterator():\n",
        "#     count = count + 1\n",
        "#   return count\n",
        "\n",
        "# def a5():\n",
        "#   count = 0\n",
        "#   for element in iter(ds):\n",
        "#     count = count + 1\n",
        "#   return count\n",
        "\n",
        "# def a6():\n",
        "#   count = 0\n",
        "#   for element in ds.take(-1):\n",
        "#     count = count + 1\n",
        "#   return count\n",
        "\n",
        "# #count = a4()\n",
        "# timeit.timeit(a6, number=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46835634999843023"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb8PCRI9mgEG",
        "outputId": "8f69a447-41c8-489d-976f-39741d32b67f"
      },
      "source": [
        "#a1 = 9.496949963000588\n",
        "#a3 = 90s?\n",
        "#a4 = 9.607164383000054\n",
        "#a5 = 9.526504041999942\n",
        "#a6 = 9.462812317000498"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.496949963000588"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    }
  ]
}