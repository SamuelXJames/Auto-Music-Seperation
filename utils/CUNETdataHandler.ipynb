{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUNETdataHandler.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNA3NDZ90+f8vhPXbpFQE85",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelXJames/Auto-Music-Seperation/blob/main/utils/CUNETdataHandler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXCB6lhnu0TG"
      },
      "source": [
        "import numpy as np\n",
        "import os, sys, math, glob, ntpath,time\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "class dataHandler:\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    \n",
        "    return None\n",
        "  \n",
        "  \n",
        "  def listFiles(self,tfr_dir,partition = None):\n",
        "    files = tf.data.Dataset.list_files(os.path.join(tfr_dir,'*.tfrec'))\n",
        "    \n",
        "    sample_file = tf.io.gfile.glob(os.path.join(tfr_dir,'*.tfrec'))[0]\n",
        "    self.getFileInfo(sample_file)\n",
        "    if partition:\n",
        "      files = files.batch(partition)\n",
        "      files = list(files.as_numpy_iterator())\n",
        "  \n",
        "    return files\n",
        "\n",
        "  def getFileInfo(self,GCS_File):\n",
        "    self.NUM_IMAGES = int(GCS_File[GCS_File.find('N')+1:GCS_File.rfind('_')])\n",
        "    w = int(GCS_File[GCS_File.find('W')+1:GCS_File.rfind('H')])\n",
        "    h = int(GCS_File[GCS_File.find('H')+1:GCS_File.rfind('N')])\n",
        "    self.NUM_CHANNELS = 1\n",
        "    self.IMG_SHAPE = (w,h,self.NUM_CHANNELS) \n",
        "    \n",
        "\n",
        "  \n",
        "  \n",
        "  @tf.function\n",
        "  def get_tfrecord(self,GCS_File):\n",
        "    dataset = tf.data.TFRecordDataset(GCS_File,compression_type='ZLIB', \n",
        "                                      num_parallel_reads = tf.data.AUTOTUNE)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "  def scaleData(self,Mixdown,Labels,Instrument):\n",
        "    Mixdown = dataset[0]\n",
        "    Labels = dataset[1]\n",
        "    Instrument = dataset[2]\n",
        "\n",
        "    Mixdown = tf.math.divide(Mixdown,255)\n",
        "    Instrument = tf.math.divide(Instrument,255)\n",
        "\n",
        "    if random.sample(range(0, 4), 1)[0] == 0:\n",
        "      p = random.uniform(0, 1)\n",
        "      Instrument = tf.math.multiply(Instrument, p)\n",
        "      Label = tf.math.multiply(Label, p) \n",
        "      \n",
        "    return Mixdown,Labels,Instrument\n",
        "  @tf.function\n",
        "  def read_tfrecord(self,example):\n",
        "    #Write this info into the filename\n",
        "    \n",
        "  # Create a dictionary describing the features.\n",
        "    features = {\n",
        "      'Mixdown': tf.io.FixedLenFeature([], tf.string),\n",
        "      'Label': tf.io.VarLenFeature(tf.float32),\n",
        "      'Instrument': tf.io.FixedLenFeature([], tf.string)\n",
        "      \n",
        "  }\n",
        "    \n",
        "    example = tf.io.parse_example(example, features)\n",
        "\n",
        "    Mixdown = tf.map_fn(tf.io.decode_png, example['Mixdown'], fn_output_signature=tf.uint8)\n",
        "    Mixdown = tf.map_fn(lambda Mixdown: tf.reshape(Mixdown, [self.IMG_SHAPE[0],\n",
        "                                                             self.IMG_SHAPE[1], \n",
        "                                                             self.NUM_CHANNELS]), Mixdown)\n",
        "    #Mixdown = tf.map_fn(lambda Mixdown: tf.cast(Mixdown, tf.float64), Mixdown, fn_output_signature=tf.float64)\n",
        "    Mixdown = tf.map_fn(lambda Mixdown: tf.divide(Mixdown,255),\n",
        "                        Mixdown, \n",
        "                        fn_output_signature = tf.float32)\n",
        "    \n",
        "    Label = tf.map_fn(tf.sparse.to_dense, example['Label'], fn_output_signature = tf.float32)\n",
        "    Label = tf.map_fn(lambda Label: tf.reshape(Label,[4,1]), Label)\n",
        "\n",
        "\n",
        "    Instrument = tf.map_fn(tf.io.decode_png, example['Instrument'], fn_output_signature=tf.uint8)\n",
        "    Instrument = tf.map_fn(lambda Instrument: tf.reshape(Instrument, [self.IMG_SHAPE[0],\n",
        "                                                                      self.IMG_SHAPE[1], \n",
        "                                                                      self.NUM_CHANNELS]), Instrument)\n",
        "    Instrument = tf.map_fn(lambda Instrument: tf.divide(Instrument,255),\n",
        "                           Instrument, \n",
        "                           fn_output_signature = tf.float32)\n",
        "    \n",
        "    if tf.random.shuffle([0,1,2,3])[0] == 0:\n",
        "      p = tf.random.uniform([1])[0] \n",
        "      Label = tf.map_fn(lambda Label: tf.math.multiply(Label,p),\n",
        "                        Label)\n",
        "      Instrument = tf.map_fn(lambda Instrument: tf.math.multiply(Instrument,p),\n",
        "                             Instrument)   \n",
        "\n",
        "    \n",
        "    \n",
        "    return Mixdown, Label, Instrument\n",
        "  \n",
        "  #@tf.function\n",
        "  def build_dataset(self,dataset, batch_size):\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.experimental_deterministic = False\n",
        "\n",
        "    #If the input is an array of file names, convert it to a dataset\n",
        "    if type(dataset) == np.ndarray:\n",
        "      dataset = tf.data.Dataset.from_tensor_slices(dataset)  \n",
        "    \n",
        "\n",
        "    dataset = dataset.interleave(self.get_tfrecord,\n",
        "                                 block_length = 1,\n",
        "                                 cycle_length = tf.data.AUTOTUNE,\n",
        "                                 num_parallel_calls = tf.data.AUTOTUNE)\n",
        "    \n",
        "    dataset = dataset.batch(batch_size, drop_remainder = False)\n",
        "  \n",
        "    dataset = dataset.map(self.read_tfrecord,num_parallel_calls = tf.data.AUTOTUNE)\n",
        "    #dataset = dataset.map(self.scaleData)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU8J7XcEs4gN"
      },
      "source": [
        "#EXAMPLE\n",
        "# dh = dataHandler()\n",
        "# files = dh.listFiles('')\n",
        "# for partion in files:\n",
        "#   ds = dh.build_dataset(partition, 32)\n",
        "#   for (LR,HR,LR_label,HR_label) in ds.take(-1):\n",
        "#       print('HR Shape: ' + str(np.shape(HR)) + ' LR Shape: ' + str(np.shape(LR)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}