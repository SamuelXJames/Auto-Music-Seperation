# -*- coding: utf-8 -*-
"""predictionPipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F6lYqTGXhzNhWhLmddWbxbaCacQ0mcZq
"""

#!pip install Pillow pydub

# A pipeline to make prediction

#Sam
#Albert


# Functions Needs
# getAudio()
# input: The filename of some audio
# ouput: An array. Each row is 5 seconds of audio

# convert_toSpec()
# input: The array from getAudio() ---> dict_object
# input: A string with the type of spectrogram ('mel' ,'db','lin') 
# output: A tensor. Each array in the tensor is a spectrogam
#############################################################
import PIL
from PIL import Image
from pydub import AudioSegment                                         
import numpy as np
import math
import tensorflow as tf
import librosa
import soundfile as sf


def myRange(start,end,step):
    i = start
    while i < end:
        yield i
        i += step
    yield end
    
def trim_audio(filename):
    
    mixture = {}
    sample = {}
    sample_np ={}
    song = AudioSegment.from_wav(filename)
    song = song.set_channels(1)
    five_seconds = 5* 1000;
    count = 0
    start = 0
    for i in myRange(5000, len(song),5000):
        mixture['%d' % count] = song[start:i]
        sample['%d' % count] = mixture[str(count)].get_array_of_samples()
        sample['%d' % count] = np.float32(sample['%d' % count])
        sample_np['%d' % count] = np.array(sample[str(count)])
        start = i
        count +=1
   # sample_np = np.float32(sample_np)
    num_zeros = len(sample_np["0"]) - len(sample_np[str(count-1)])
    #np.zeros(num_zeros)
    sample_np[str(count-1)] = np.hstack((sample_np[str(count-1)], np.zeros(num_zeros)))
    return sample_np
#SR: 22050
#filename (input of the trim_audio function) : "mixture.wav" 
#sample_np = {"0" : array, "1": array, "2": array .. }



def scale_minmax(X, min=0.0, max=1.0):
    X_std = (X - X.min()) / (X.max() - X.min())
    X_scaled = X_std * (max - min) + min
    return X_scaled

def convert_toSpec(dict_object, pp_type):
  n_fft = 2048
  hop_length = 512
  n_mels = 512
  return_list = [] 
  if pp_type.lower() == 'lin':
    for key, value in dict_object.items():   
     
      D = librosa.stft(value, n_fft=n_fft,  hop_length=hop_length)
      D = scale_minmax(D, 0,255)
    
      D = np.flip(D, axis=0) # put low frequencies at the bottom in image
      
      img = 255 - D

      return_list.append(scale_minmax(img,0,1).astype(np.float32))


      
  elif pp_type.lower() == 'psdb':
    for key, value in dict_object.items():
      D = np.abs(librosa.stft(value, n_fft=n_fft,  hop_length=hop_length))
      DB = librosa.amplitude_to_db(D, ref=np.max)####
      DB = DB.astype(np.uint8)

      DB = librosa.stft(y, n_fft=n_fft,  hop_length=hop_length)
    #DB = librosa.amplitude_to_db(D,ref=np.max)
    #DB= np.float32(DB)
      DB = scale_minmax(DB, 0,255)

   

      #DB = scale_minmax(DB, 0, 1).astype(np.float32)
      return_list.append(scale_minmax(DB,0,1).astype(np.float32))
      
  elif pp_type.lower() == 'mel':
    for key, value in dict_object.items():
      S = librosa.feature.melspectrogram(value, sr=22050, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)
      S_DB = librosa.power_to_db(S, ref=np.max).astype(np.int8)
      #S_DB = scale_minmax(S_DB, 0, 1).astype(np.float32)
      return_list.append(scale_minmax(S_DB,0,1).astype(np.float32))

  else:
    print('please input preprocess type')

  return np.array(return_list)
# return_list = []
# PP_DATA1 = [1,2,3,4,5]
# PP_DATA2 = [1,2,3,4,5]
# return_list.append(PP_DATA)
# .....
# [[1,2,3,4,5], [1,2,3,4,5]]

# Predict()
# input: the tensor from convert Spec
# output: The predicted tensor

# convert_toAudio()
# input: A tensor, where each array in the tensor is a spectrogram
# input: a folder, where to save the audio files
# output: None - 
#         Converts the spectrograms into audio 
#         Parses the audio into one audio file (or multiple songs if the intoput to getAudio was multiple songs)
#         Saves audio to the output folder








def convert_toAudio(track,PATH,Type):
  n_fft = 2048
  hop_length = 512
  n_mels = 512
  y = []
  #track = track*255
  for i in range(np.shape(track)[0]):
    image = track[i,:,:]
    image = scale_minmax(image,0,255).astype('int') 
    if Type=='lin':
        #Specto
        #image = Image.open(track)
        #image = asarray(image)
        image = 255 - image
        image = np.flip(image,axis=0)


        image = np.float32(image)
        data = scale_minmax(image, -1,1)

        y.append(librosa.core.istft(data, hop_length=hop_length))

    elif Type== 'psdb':
        #Power Spec
        #image = Image.open(track)
        #data = asarray(image)
        data = image
        data = np.float64(data)
        data = librosa.db_to_amplitude(data)
        y.append(librosa.core.istft(data, hop_length=hop_length))
        #Declare path to output file!
        

    elif Type == 'mel':
        #image = Image.open(track)
        #data = asarray(image)
        data=image
        data = np.int8(data)
        data = librosa.db_to_power(data)
        y.append(librosa.feature.inverse.mel_to_audio(data, n_fft=n_fft, hop_length=hop_length))
        #Declare path to output file!
        

    else:
      print('please input preprocess type')
  #y = np.asarray(y[0])
  y = np.reshape(y,(-1,1))
  y = scale_minmax(y, -1, 1).astype(np.float32)
  sf.write(PATH,y,44100)
  #return y

def predict(model,spectrograms):
  dataset = tf.data.Dataset.from_tensor_slices(spectrograms)

  if spectrograms.ndim == 3:
    dataset = dataset.batch(1)
  
  output_spectrograms = model.predict(dataset,
                                      verbose = 1)
  
  return output_spectrograms


#for i in range(np.shape(tensor)[0]):
#  spectrogram = tensor[i,:,:]




def getPrediction(model,filename, type, PATH = None):
  audio = trim_audio(filename)
  spec = convert_toSpec(audio, type)
  prediction = predict(model,spec)

  if type != 'psdb':
    convert_toAudio(prediction,PATH,type')
    return None
  else:
    return prediction
