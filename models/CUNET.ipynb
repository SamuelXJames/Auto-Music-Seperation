{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUNET.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtIXnHkv/1ElG0VHQELnDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelXJames/Auto-Music-Seperation/blob/main/models/CUNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVS4n-MnKMbS"
      },
      "source": [
        "# @ Author: https://github.com/gabolsgabs/cunet\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, multiply, BatchNormalization, Conv1D, Dropout, Lambda,\n",
        "    Concatenate, Conv2DTranspose, Dense, LeakyReLU,ZeroPadding2D,Cropping2D)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "#from models.CUNET_config import config\n",
        "from CUNET_config import config\n",
        "\n",
        "def FiLM_simple_layer():\n",
        "    \"\"\"multiply scalar to a tensor\"\"\"\n",
        "    def func(args):\n",
        "        x, gamma, beta = args\n",
        "        s = list(x.shape)\n",
        "        s[0] = 1\n",
        "        # avoid tile with the num of batch -> it is the same for both tensors\n",
        "        g = tf.tile(tf.expand_dims(tf.expand_dims(gamma, 2), 3), s)\n",
        "        b = tf.tile(tf.expand_dims(tf.expand_dims(beta, 2), 3), s)\n",
        "        return tf.add(b, tf.multiply(x, g))\n",
        "    return Lambda(func)\n",
        "\n",
        "def slice_tensor(position):\n",
        "    # Crops (or slices) a Tensor\n",
        "    def func(x):\n",
        "        return x[:, :, position]\n",
        "    return Lambda(func)\n",
        "\n",
        "\n",
        "def cnn_block(\n",
        "    x, n_filters, kernel_size, padding, initializer, activation='relu'\n",
        "):\n",
        "    for i, (f, p) in enumerate(zip(n_filters, padding)):\n",
        "        extra = i != 0\n",
        "        x = Conv1D(f, kernel_size, padding=p, activation=activation,\n",
        "                   kernel_initializer=initializer)(x)\n",
        "        if extra:\n",
        "            x = Dropout(0.5)(x)\n",
        "            x = BatchNormalization(momentum=0.9, scale=True)(x)\n",
        "    return x\n",
        "\n",
        "def cnn_control(n_conditions, n_filters):\n",
        "    \"\"\"\n",
        "    For simple dense control:\n",
        "        - n_conditions = 6\n",
        "        - n_filters = [16, 32, 128]\n",
        "    For complex dense control:\n",
        "        - n_conditions = 1008\n",
        "        - n_filters = [16, 32, 64]\n",
        "    \"\"\"\n",
        "    input_conditions = Input(shape=(config.Z_DIM, 1), name = 'Film Input')\n",
        "    initializer = tf.random_normal_initializer(stddev=0.02)\n",
        "    cnn = cnn_block(\n",
        "        input_conditions, n_filters, config.Z_DIM, config.PADDING, initializer\n",
        "    )\n",
        "    gammas = Dense(\n",
        "        n_conditions, input_dim=n_filters[-1], activation=config.ACT_G,\n",
        "        kernel_initializer=initializer\n",
        "    )(cnn)\n",
        "    betas = Dense(\n",
        "        n_conditions, input_dim=n_filters[-1], activation=config.ACT_B,\n",
        "        kernel_initializer=initializer\n",
        "    )(cnn)\n",
        "    # both = Add()([gammas, betas])\n",
        "    return input_conditions, gammas, betas\n",
        "\n",
        "def get_activation(name):\n",
        "    if name == 'leaky_relu':\n",
        "        return LeakyReLU(alpha=0.2)\n",
        "    return tf.keras.activations.get(name)\n",
        "\n",
        "\n",
        "def u_net_conv_block(\n",
        "    x, n_filters, initializer, gamma, beta, activation, film_type,\n",
        "    kernel_size=(5, 5), strides=(2, 2), padding='same'\n",
        "):\n",
        "    x = Conv2D(n_filters, kernel_size=kernel_size,  padding=padding,\n",
        "               strides=strides, kernel_initializer=initializer)(x)\n",
        "    x = BatchNormalization(momentum=0.9, scale=True)(x)\n",
        "    x = FiLM_simple_layer()([x, gamma, beta])\n",
        "    \n",
        "    x = get_activation(activation)(x)\n",
        "    return x\n",
        "\n",
        "def u_net_deconv_block(\n",
        "    x, x_encod, n_filters, initializer, activation, dropout, skip,\n",
        "    kernel_size=(5, 5), strides=(2, 2), padding='same'\n",
        "):\n",
        "    if skip:\n",
        "        x = Concatenate(axis=3)([x, x_encod])\n",
        "    x = Conv2DTranspose(\n",
        "        n_filters, kernel_size=kernel_size, padding=padding, strides=strides,\n",
        "        kernel_initializer=initializer)(x)\n",
        "    x = BatchNormalization(momentum=0.9, scale=True)(x)\n",
        "    if dropout:\n",
        "        x = Dropout(0.5)(x)\n",
        "    x = get_activation(activation)(x)\n",
        "    return x\n",
        "\n",
        "def getPaddingShape(input_shape):\n",
        "  output_shape = [input]\n",
        "  ax1 = (2**np.ceil(np.log2(input_shape[0]))) - input_shape[0]\n",
        "  a = int(np.floor(ax1/2))\n",
        "  b = int(np.ceil(ax1/2))\n",
        "\n",
        "  ax2 = (2**np.ceil(np.log2(input_shape[1]))) - input_shape[1]\n",
        "  c = int(np.floor(ax2/2))\n",
        "  d = int(np.ceil(ax2/2))\n",
        "  return a,b,c,d\n",
        "\n",
        "def cunet_model(shape = (334,217,1)):\n",
        "    inputs = Input(shape=shape)#[512,128,1]\n",
        "    n_layers = config.N_LAYERS\n",
        "    a,b,c,d = getPaddingShape(input_shape = shape)\n",
        "    x = inputs\n",
        "    x = ZeroPadding2D(((a,b),(c,d)))(x)\n",
        "    encoder_layers = []\n",
        "    initializer = tf.random_normal_initializer(stddev=0.02)\n",
        "\n",
        "    input_conditions, gammas, betas = cnn_control(n_conditions=config.N_CONDITIONS, \n",
        "                                                  n_filters=config.N_FILTERS)\n",
        "    # Encoder\n",
        "    complex_index = 0\n",
        "    for i in range(n_layers):\n",
        "        n_filters = config.FILTERS_LAYER_1 * (2 ** i)\n",
        "        gamma, beta = slice_tensor(i)(gammas), slice_tensor(i)(betas)\n",
        "        \n",
        "        x = u_net_conv_block(\n",
        "            x, n_filters, initializer, gamma, beta,\n",
        "            activation=config.ACTIVATION_ENCODER, film_type=config.FILM_TYPE\n",
        "        )\n",
        "        encoder_layers.append(x)\n",
        "    # Decoder\n",
        "    for i in range(n_layers):\n",
        "        # parameters each decoder layer\n",
        "        is_final_block = i == n_layers - 1  # the las layer is different\n",
        "        # not dropout in the first block and the last two encoder blocks\n",
        "        dropout = not (i == 0 or i == n_layers - 1 or i == n_layers - 2)\n",
        "        # for getting the number of filters\n",
        "        encoder_layer = encoder_layers[n_layers - i - 1]\n",
        "        skip = i > 0    # not skip in the first encoder block\n",
        "        if is_final_block:\n",
        "            n_filters = 1\n",
        "            activation = config.ACT_LAST\n",
        "        else:\n",
        "            n_filters = encoder_layer.get_shape().as_list()[-1] // 2\n",
        "            activation = config.ACTIVATION_DECODER\n",
        "        x = u_net_deconv_block(\n",
        "            x, encoder_layer, n_filters, initializer, activation, dropout, skip\n",
        "        )\n",
        "    x = Cropping2D(((a,b), (c,d)))(x)\n",
        "    outputs = multiply([inputs, x])\n",
        "    model = Model(inputs=[inputs, input_conditions], outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}